# Hallucination Boundaries in Prompt Design

**Author:** SignalFrame  
**Type:** Design ethics note  
**Status:** Living document

---

## Premise

Large language models are not neutral. They are prediction engines trained on latent bias, implicit context, and surface-level structure. In high-stakes domains, hallucination is not noiseâ€”itâ€™s *risk.*

---

## Boundaries That Protect

### âœ… Acceptable Techniques
- â€œOnly include information present in the inputâ€  
- Explicit field labeling  
- Output format constraints (e.g., bullet-first, label-colon)  
- Scope separation (e.g., instruction vs. metadata)

### ðŸš« Dangerous Techniques
- â€œSummarize in your own wordsâ€ without scoping  
- â€œSimplify thisâ€ in clinical/legal contexts  
- Any instruction lacking an inference boundary  
- Broad use of â€œrelevant,â€ â€œimportant,â€ or â€œsignificantâ€

---

## SignalFrame Principle

> *Contain hallucination by design. Not by correction.*

Prompt systems should enforce *clarity through constraint*, not after-the-fact review.

---

This document evolves with usage. For implementation examples, see:
- `emr-triage-summary/V2_prompt.md`
- `legal-contract-clause-extractor/V1_prompt.md`

