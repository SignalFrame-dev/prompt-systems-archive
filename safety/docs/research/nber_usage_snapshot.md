# External Evidence Snapshot — ChatGPT Usage (NBER WP34255, Sept 2025)

This note captures high-signal findings from *How People Use ChatGPT* (NBER Working Paper 34255, Sept 2025). It’s descriptive evidence used to validate SignalFrame’s scope; no policy “shoulds/coulds” included.

## Key measurements
- Non-work share: ~70% of consumer messages by mid-2025.
- Work usage composition: Writing dominates (≈40–50% of work messages across roles).
- Top activity clusters (≈80% of all messages): Practical Guidance, Seeking Information, Writing.
- User intent (taxonomy): ~49% Asking (decision support), ~40% Doing (outputs), ~11% Expressing.
- Occupational tilt: Educated/professional users rely more on Asking (guidance/decision support).

## Relevance to SignalFrame
- Validates focus on writing-heavy, decision-support workflows (EMR, Legal, Accommodations).
- Justifies adversarial tests framed by Asking vs Doing (failure modes differ by intent).
- Supports prioritizing “hardened outputs” over novelty demos; this is where real usage concentrates.

## How we use this
- Roadmap alignment: keep core systems in the Writing/Guidance band.
- Test design: include Asking-mode probes (ambiguity, misinterpretation) and Doing-mode probes (format-gaming, partial extraction).
- Evidence ledger: this file lives in `safety/docs/research/` and can be superseded by newer snapshots without touching README.

## Citation
NBER Working Paper 34255 (Sept 2025), *How People Use ChatGPT*.  
Direct link: [https://www.nber.org/system/files/working_papers/w34255/w34255.pdf](https://www.nber.org/system/files/working_papers/w34255/w34255.pdf)
